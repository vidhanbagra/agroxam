# -*- coding: utf-8 -*-
"""Copy of NormalCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_hMqIjsdSXUk_9734f9gZGROY6XMWgsr
"""

# Check GPU
!nvidia-smi

# Import necessary libraries
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
import shutil
from zipfile import ZipFile
from google.colab import files

from google.colab import drive
drive.mount('/content/drive')

!ls "/content/drive/My Drive/your_folder"

!unzip "/content/drive/My Drive/your_folder/leaf_data_training.zip" -d /content/leaf_data_training

!ls "/content/drive/My Drive/"

from google.colab import drive
drive.mount('/content/drive')

# Now unzip with correct path
!unzip "/content/drive/My Drive/leaf_data_training.zip" -d /content/leaf_data_training

# Check extracted folders
import os
print(os.listdir("/content/leaf_data_training"))

import os
import shutil

valid_classes = ['Healthy', 'Leaf_Minor_Infestation', 'Mosaic_Virus']
src_base = "/content/leaf_data_training"
clean_dir = "/content/clean_dataset"

os.makedirs(clean_dir, exist_ok=True)

for class_name in valid_classes:
    src = os.path.join(src_base, class_name)
    dst = os.path.join(clean_dir, class_name)
    if os.path.exists(src):
        shutil.move(src, dst)

print("✅ Clean dataset folders:", os.listdir(clean_dir))

import random

train_ratio = 0.7
val_ratio = 0.2
test_ratio = 0.1

split_base = "/content/split_dataset"
for split in ['train', 'val', 'test']:
    for cls in valid_classes:
        os.makedirs(os.path.join(split_base, split, cls), exist_ok=True)

for cls in valid_classes:
    cls_path = os.path.join(clean_dir, cls)
    images = os.listdir(cls_path)
    random.shuffle(images)

    total = len(images)
    train_count = int(total * train_ratio)
    val_count = int(total * val_ratio)

    for i, img in enumerate(images):
        src = os.path.join(cls_path, img)
        if i < train_count:
            dst = os.path.join(split_base, 'train', cls, img)
        elif i < train_count + val_count:
            dst = os.path.join(split_base, 'val', cls, img)
        else:
            dst = os.path.join(split_base, 'test', cls, img)
        shutil.move(src, dst)

import os
print(os.listdir("/content/leaf_data_training"))

import os
import shutil

valid_classes = ['Healthy', 'Leaf_Minor_Infestation', 'Mosaic_Virus']
src_base = "/content/leaf_data_training/leaf_data_training"  # Updated path here
clean_dir = "/content/clean_dataset"

os.makedirs(clean_dir, exist_ok=True)

for class_name in valid_classes:
    src = os.path.join(src_base, class_name)
    dst = os.path.join(clean_dir, class_name)
    if os.path.exists(src):
        shutil.move(src, dst)

print("✅ Clean dataset folders:", os.listdir(clean_dir))

import os
import random
import shutil

valid_classes = ['Healthy', 'Leaf_Minor_Infestation', 'Mosaic_Virus']
train_ratio = 0.7
val_ratio = 0.2
test_ratio = 0.1

clean_dir = "/content/clean_dataset"
split_base = "/content/split_dataset"

# Create split directories
for split in ['train', 'val', 'test']:
    for cls in valid_classes:
        os.makedirs(os.path.join(split_base, split, cls), exist_ok=True)

# Split and move images
for cls in valid_classes:
    cls_path = os.path.join(clean_dir, cls)
    images = os.listdir(cls_path)
    random.shuffle(images)

    total = len(images)
    train_count = int(total * train_ratio)
    val_count = int(total * val_ratio)

    for i, img in enumerate(images):
        src = os.path.join(cls_path, img)
        if i < train_count:
            dst = os.path.join(split_base, 'train', cls, img)
        elif i < train_count + val_count:
            dst = os.path.join(split_base, 'val', cls, img)
        else:
            dst = os.path.join(split_base, 'test', cls, img)
        shutil.move(src, dst)

import tensorflow as tf

img_size = (224, 224)
batch_size = 32

train_ds = tf.keras.utils.image_dataset_from_directory(
    os.path.join(split_base, "train"),
    image_size=img_size,
    batch_size=batch_size
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    os.path.join(split_base, "val"),
    image_size=img_size,
    batch_size=batch_size
)

test_ds = tf.keras.utils.image_dataset_from_directory(
    os.path.join(split_base, "test"),
    image_size=img_size,
    batch_size=batch_size
)

# Optimize performance
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)

from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Rescaling(1./255, input_shape=(224, 224, 3)),

    layers.Conv2D(32, 3, activation='relu'),
    layers.MaxPooling2D(),

    layers.Conv2D(64, 3, activation='relu'),
    layers.MaxPooling2D(),

    layers.Conv2D(128, 3, activation='relu'),
    layers.MaxPooling2D(),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(3, activation='softmax')  # 3 classes
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=20,
    callbacks=[callback]
)

test_loss, test_acc = model.evaluate(test_ds)
print(f"\n✅ Test Accuracy: {test_acc * 100:.2f}%")

from sklearn.metrics import classification_report, accuracy_score
import numpy as np

y_true = []
y_pred = []

for images, labels in test_ds:
    preds = model.predict(images, verbose=0)

    # labels are already integers, so no argmax needed
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(preds, axis=1))

# Convert to NumPy arrays
y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Accuracy
accuracy = accuracy_score(y_true, y_pred) * 100
print(f"✅ Accuracy: {accuracy:.2f}%\n")

# Precision, Recall, F1 Score per class
from sklearn.metrics import classification_report
class_names = ['Healthy', 'Leaf_Minor_Infestation', 'Mosaic_Virus']  # adjust if needed

print("✅ Classification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_names))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

cm = confusion_matrix(y_true, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)

plt.figure(figsize=(8, 6))
disp.plot(cmap="Blues", values_format='d')
plt.title("✅ Confusion Matrix")
plt.show()